{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76381050",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prior to execute this notebook, please make sure you have already cloned the sample data\n",
    "#!git clone https://github.com/xieyongliang/all-in-one-ai-sample-data.git -t ../../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7437fd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.pytorch.model import PyTorchModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46aabd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8329741e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate.py\n",
      "finetune.py\n",
      "inference.py\n",
      "model.py\n",
      "paddlenlp.ipynb\n",
      "requirements.txt\n",
      "uie_predictor.py\n",
      "utils.py\n"
     ]
    }
   ],
   "source": [
    "!rm -rf sourcedir.tar.gz\n",
    "!tar czvf sourcedir.tar.gz *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02a4f091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./sourcedir.tar.gz to s3://sagemaker-ap-east-1-034068151705/paddlenlp/source/sourcedir.tar.gz\n"
     ]
    }
   ],
   "source": [
    "source_dir = 's3://{0}/{1}/source/'.format(bucket, 'paddlenlp')\n",
    "!aws s3 cp sourcedir.tar.gz $source_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e1f61db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ../../../all-in-one-ai-sample-data/paddlenlp/train/test.txt to s3://sagemaker-ap-east-1-034068151705/paddlenlp/data/train/test.txt\n",
      "upload: ../../../all-in-one-ai-sample-data/paddlenlp/train/train.txt to s3://sagemaker-ap-east-1-034068151705/paddlenlp/data/train/train.txt\n",
      "upload: ../../../all-in-one-ai-sample-data/paddlenlp/train/dev.txt to s3://sagemaker-ap-east-1-034068151705/paddlenlp/data/train/dev.txt\n"
     ]
    }
   ],
   "source": [
    "train_dir = 's3://{0}/{1}/data/train'.format(bucket, 'paddlenlp')\n",
    "!aws s3 cp ../../../all-in-one-ai-sample-data/paddlenlp/train/ $train_dir --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "102bf195",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = None\n",
    "entry_point = 'finetune.py'\n",
    "source_dir = '{0}sourcedir.tar.gz'.format(source_dir)\n",
    "git_config = None\n",
    "role = role\n",
    "hyperparameters = {\n",
    "    'train_path': '/opt/ml/input/data/dataset/train.txt',\n",
    "    'dev_path': '/opt/ml/input/data/dataset/dev.txt', \n",
    "    'save_dir': '/opt/ml/model',                 \n",
    "    'batch_size' : 16, \n",
    "    'learning_rate' : 1e-5, \n",
    "    'max_seq_len' : 512,\n",
    "    'num_epochs' : 100,\n",
    "    'seed' : 1000,\n",
    "    'logging_steps': 10,\n",
    "    'valid_steps': 100,\n",
    "    'device': 'gpu',\n",
    "    'model': 'uie-base'\n",
    "}\n",
    "framework_version = '1.9.0'\n",
    "py_version = 'py38'\n",
    "instance_type = 'ml.g4dn.16xlarge'\n",
    "instance_count = 1\n",
    "inputs = {\n",
    "    'dataset': train_dir\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a9268ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-ap-east-1-034068151705/paddlenlp/source/sourcedir.tar.gz\n"
     ]
    }
   ],
   "source": [
    "print(source_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42ea6c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = PyTorch(\n",
    "    entry_point = entry_point,\n",
    "    source_dir = source_dir,\n",
    "    git_config = git_config,\n",
    "    role = role,\n",
    "    debugger_hook_config = False,\n",
    "    hyperparameters = hyperparameters,\n",
    "    framework_version = framework_version, \n",
    "    py_version = py_version,\n",
    "    instance_type = instance_type,\n",
    "    instance_count = instance_count\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9c171f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-13 07:56:26 Starting - Starting the training job...\n",
      "2022-09-13 07:56:42 Starting - Preparing the instances for trainingProfilerReport-1663055786: InProgress\n",
      "......\n",
      "2022-09-13 07:57:51 Downloading - Downloading input data...\n",
      "2022-09-13 07:58:12 Training - Downloading the training image.....................\n",
      "2022-09-13 08:01:53 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2022-09-13 08:01:45,239 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2022-09-13 08:01:45,263 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2022-09-13 08:01:45,268 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2022-09-13 08:01:45,549 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting paddlenlp\u001b[0m\n",
      "\u001b[34mDownloading paddlenlp-2.4.0-py3-none-any.whl (1.8 MB)\u001b[0m\n",
      "\u001b[34mCollecting onnx\u001b[0m\n",
      "\u001b[34mDownloading onnx-1.12.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\u001b[0m\n",
      "\u001b[34mCollecting onnxconverter_common\u001b[0m\n",
      "\u001b[34mDownloading onnxconverter_common-1.12.2-py2.py3-none-any.whl (83 kB)\u001b[0m\n",
      "\u001b[34mCollecting datasets>=2.0.0\u001b[0m\n",
      "\u001b[34mDownloading datasets-2.4.0-py3-none-any.whl (365 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf<=3.20.0,>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from paddlenlp->-r requirements.txt (line 1)) (3.18.1)\u001b[0m\n",
      "\u001b[34mCollecting sentencepiece\u001b[0m\n",
      "\u001b[34mDownloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\u001b[0m\n",
      "\u001b[34mCollecting paddlefsl\u001b[0m\n",
      "\u001b[34mDownloading paddlefsl-1.1.0-py3-none-any.whl (101 kB)\u001b[0m\n",
      "\u001b[34mCollecting paddle2onnx\u001b[0m\n",
      "\u001b[34mDownloading paddle2onnx-1.0.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess<=0.70.12.2 in /opt/conda/lib/python3.8/site-packages (from paddlenlp->-r requirements.txt (line 1)) (0.70.12.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: colorama in /opt/conda/lib/python3.8/site-packages (from paddlenlp->-r requirements.txt (line 1)) (0.4.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill<0.3.5 in /opt/conda/lib/python3.8/site-packages (from paddlenlp->-r requirements.txt (line 1)) (0.3.4)\u001b[0m\n",
      "\u001b[34mCollecting seqeval\u001b[0m\n",
      "\u001b[34mDownloading seqeval-1.2.2.tar.gz (43 kB)\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting colorlog\u001b[0m\n",
      "\u001b[34mDownloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\u001b[0m\n",
      "\u001b[34mCollecting jieba\u001b[0m\n",
      "\u001b[34mDownloading jieba-0.42.1.tar.gz (19.2 MB)\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from paddlenlp->-r requirements.txt (line 1)) (4.61.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.16.6 in /opt/conda/lib/python3.8/site-packages (from onnx->-r requirements.txt (line 2)) (1.19.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.6.2.1 in /opt/conda/lib/python3.8/site-packages (from onnx->-r requirements.txt (line 2)) (3.10.0.2)\u001b[0m\n",
      "\u001b[34mCollecting tqdm\u001b[0m\n",
      "\u001b[34mDownloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\u001b[0m\n",
      "\u001b[34mCollecting huggingface-hub<1.0.0,>=0.1.0\u001b[0m\n",
      "\u001b[34mDownloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\u001b[0m\n",
      "\u001b[34mCollecting xxhash\u001b[0m\n",
      "\u001b[34mDownloading xxhash-3.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from datasets>=2.0.0->paddlenlp->-r requirements.txt (line 1)) (21.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from datasets>=2.0.0->paddlenlp->-r requirements.txt (line 1)) (1.2.4)\u001b[0m\n",
      "\u001b[34mCollecting responses<0.19\u001b[0m\n",
      "\u001b[34mDownloading responses-0.18.0-py3-none-any.whl (38 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.8/site-packages (from datasets>=2.0.0->paddlenlp->-r requirements.txt (line 1)) (2.26.0)\u001b[0m\n",
      "\u001b[34mCollecting aiohttp\u001b[0m\n",
      "\u001b[34mDownloading aiohttp-3.8.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.3 MB)\u001b[0m\n",
      "\u001b[34mCollecting pyarrow>=6.0.0\u001b[0m\n",
      "\u001b[34mDownloading pyarrow-9.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.3 MB)\u001b[0m\n",
      "\u001b[34mCollecting fsspec[http]>=2021.11.1\u001b[0m\n",
      "\u001b[34mDownloading fsspec-2022.8.2-py3-none-any.whl (140 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.8/site-packages (from seqeval->paddlenlp->-r requirements.txt (line 1)) (0.24.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp->-r requirements.txt (line 1)) (21.2.0)\u001b[0m\n",
      "\u001b[34mCollecting yarl<2.0,>=1.0\u001b[0m\n",
      "\u001b[34mDownloading yarl-1.8.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (262 kB)\u001b[0m\n",
      "\u001b[34mCollecting async-timeout<5.0,>=4.0.0a3\u001b[0m\n",
      "\u001b[34mDownloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting frozenlist>=1.1.1\u001b[0m\n",
      "\u001b[34mDownloading frozenlist-1.3.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\u001b[0m\n",
      "\u001b[34mCollecting multidict<7.0,>=4.5\u001b[0m\n",
      "\u001b[34mDownloading multidict-6.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (121 kB)\u001b[0m\n",
      "\u001b[34mCollecting aiosignal>=1.1.2\u001b[0m\n",
      "\u001b[34mDownloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp->-r requirements.txt (line 1)) (2.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets>=2.0.0->paddlenlp->-r requirements.txt (line 1)) (5.4.1)\u001b[0m\n",
      "\u001b[34mCollecting filelock\u001b[0m\n",
      "\u001b[34mDownloading filelock-3.8.0-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->datasets>=2.0.0->paddlenlp->-r requirements.txt (line 1)) (2.4.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets>=2.0.0->paddlenlp->-r requirements.txt (line 1)) (2021.10.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets>=2.0.0->paddlenlp->-r requirements.txt (line 1)) (2.10)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets>=2.0.0->paddlenlp->-r requirements.txt (line 1)) (1.26.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp->-r requirements.txt (line 1)) (1.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp->-r requirements.txt (line 1)) (2.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp->-r requirements.txt (line 1)) (1.7.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets>=2.0.0->paddlenlp->-r requirements.txt (line 1)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets>=2.0.0->paddlenlp->-r requirements.txt (line 1)) (2021.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->datasets>=2.0.0->paddlenlp->-r requirements.txt (line 1)) (1.16.0)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: jieba, seqeval\u001b[0m\n",
      "\u001b[34mBuilding wheel for jieba (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for jieba (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314477 sha256=a6d0fe5921fc6439396697cddc9f40cffc61004fad35fc919022366789bb8103\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/ca/38/d8/dfdfe73bec1d12026b30cb7ce8da650f3f0ea2cf155ea018ae\u001b[0m\n",
      "\u001b[34mBuilding wheel for seqeval (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for seqeval (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16181 sha256=60c776f739d976b6e5591ea66032a172747468ce2599d68ee5e1b9dc685cc8dd\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/ad/5c/ba/05fa33fa5855777b7d686e843ec07452f22a66a138e290e732\u001b[0m\n",
      "\u001b[34mSuccessfully built jieba seqeval\u001b[0m\n",
      "\u001b[34mInstalling collected packages: multidict, frozenlist, yarl, async-timeout, aiosignal, tqdm, fsspec, filelock, aiohttp, xxhash, responses, pyarrow, huggingface-hub, seqeval, sentencepiece, paddlefsl, paddle2onnx, onnx, jieba, datasets, colorlog, paddlenlp, onnxconverter-common\u001b[0m\n",
      "\u001b[34mAttempting uninstall: tqdm\u001b[0m\n",
      "\u001b[34mFound existing installation: tqdm 4.61.2\u001b[0m\n",
      "\u001b[34mUninstalling tqdm-4.61.2:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled tqdm-4.61.2\u001b[0m\n",
      "\u001b[34mAttempting uninstall: fsspec\u001b[0m\n",
      "\u001b[34mFound existing installation: fsspec 2021.10.0\u001b[0m\n",
      "\u001b[34mUninstalling fsspec-2021.10.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled fsspec-2021.10.0\u001b[0m\n",
      "\u001b[34mAttempting uninstall: pyarrow\u001b[0m\n",
      "\u001b[34mFound existing installation: pyarrow 5.0.0\u001b[0m\n",
      "\u001b[34mUninstalling pyarrow-5.0.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled pyarrow-5.0.0\u001b[0m\n",
      "\u001b[34mSuccessfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 colorlog-6.7.0 datasets-2.4.0 filelock-3.8.0 frozenlist-1.3.1 fsspec-2022.8.2 huggingface-hub-0.9.1 jieba-0.42.1 multidict-6.0.2 onnx-1.12.0 onnxconverter-common-1.12.2 paddle2onnx-1.0.0 paddlefsl-1.1.0 paddlenlp-2.4.0 pyarrow-9.0.0 responses-0.18.0 sentencepiece-0.1.97 seqeval-1.2.2 tqdm-4.64.1 xxhash-3.0.0 yarl-1.8.1\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m2022-09-13 08:02:02,371 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"dataset\": \"/opt/ml/input/data/dataset\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch_size\": 16,\n",
      "        \"dev_path\": \"/opt/ml/input/data/dataset/dev.txt\",\n",
      "        \"device\": \"gpu\",\n",
      "        \"learning_rate\": 1e-05,\n",
      "        \"logging_steps\": 10,\n",
      "        \"max_seq_len\": 512,\n",
      "        \"model\": \"uie-base\",\n",
      "        \"num_epochs\": 100,\n",
      "        \"save_dir\": \"/opt/ml/model\",\n",
      "        \"seed\": 1000,\n",
      "        \"train_path\": \"/opt/ml/input/data/dataset/train.txt\",\n",
      "        \"valid_steps\": 100\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"dataset\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2022-09-13-07-56-26-024\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-ap-east-1-034068151705/paddlenlp/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"finetune\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g4dn.16xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g4dn.16xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"finetune.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch_size\":16,\"dev_path\":\"/opt/ml/input/data/dataset/dev.txt\",\"device\":\"gpu\",\"learning_rate\":1e-05,\"logging_steps\":10,\"max_seq_len\":512,\"model\":\"uie-base\",\"num_epochs\":100,\"save_dir\":\"/opt/ml/model\",\"seed\":1000,\"train_path\":\"/opt/ml/input/data/dataset/train.txt\",\"valid_steps\":100}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=finetune.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.16xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.16xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"dataset\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"dataset\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=finetune\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=64\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-ap-east-1-034068151705/paddlenlp/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"dataset\":\"/opt/ml/input/data/dataset\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch_size\":16,\"dev_path\":\"/opt/ml/input/data/dataset/dev.txt\",\"device\":\"gpu\",\"learning_rate\":1e-05,\"logging_steps\":10,\"max_seq_len\":512,\"model\":\"uie-base\",\"num_epochs\":100,\"save_dir\":\"/opt/ml/model\",\"seed\":1000,\"train_path\":\"/opt/ml/input/data/dataset/train.txt\",\"valid_steps\":100},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"dataset\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2022-09-13-07-56-26-024\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-east-1-034068151705/paddlenlp/source/sourcedir.tar.gz\",\"module_name\":\"finetune\",\"network_interface_name\":\"eth0\",\"num_cpus\":64,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.16xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.16xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"finetune.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch_size\",\"16\",\"--dev_path\",\"/opt/ml/input/data/dataset/dev.txt\",\"--device\",\"gpu\",\"--learning_rate\",\"1e-05\",\"--logging_steps\",\"10\",\"--max_seq_len\",\"512\",\"--model\",\"uie-base\",\"--num_epochs\",\"100\",\"--save_dir\",\"/opt/ml/model\",\"--seed\",\"1000\",\"--train_path\",\"/opt/ml/input/data/dataset/train.txt\",\"--valid_steps\",\"100\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_DATASET=/opt/ml/input/data/dataset\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH_SIZE=16\u001b[0m\n",
      "\u001b[34mSM_HP_DEV_PATH=/opt/ml/input/data/dataset/dev.txt\u001b[0m\n",
      "\u001b[34mSM_HP_DEVICE=gpu\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=1e-05\u001b[0m\n",
      "\u001b[34mSM_HP_LOGGING_STEPS=10\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_SEQ_LEN=512\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL=uie-base\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_EPOCHS=100\u001b[0m\n",
      "\u001b[34mSM_HP_SAVE_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_HP_SEED=1000\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN_PATH=/opt/ml/input/data/dataset/train.txt\u001b[0m\n",
      "\u001b[34mSM_HP_VALID_STEPS=100\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 finetune.py --batch_size 16 --dev_path /opt/ml/input/data/dataset/dev.txt --device gpu --learning_rate 1e-05 --logging_steps 10 --max_seq_len 512 --model uie-base --num_epochs 100 --save_dir /opt/ml/model --seed 1000 --train_path /opt/ml/input/data/dataset/train.txt --valid_steps 100\u001b[0m\n",
      "\u001b[34mCollecting paddlepaddle-gpu\u001b[0m\n",
      "\u001b[34mDownloading paddlepaddle_gpu-2.3.2-cp38-cp38-manylinux1_x86_64.whl (394.0 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: Pillow in /opt/conda/lib/python3.8/site-packages (from paddlepaddle-gpu) (8.3.2)\u001b[0m\n",
      "\u001b[34mCollecting paddle-bfloat==0.1.7\u001b[0m\n",
      "\u001b[34mDownloading paddle_bfloat-0.1.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (385 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from paddlepaddle-gpu) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.13 in /opt/conda/lib/python3.8/site-packages (from paddlepaddle-gpu) (1.19.1)\u001b[0m\n",
      "\u001b[34mCollecting astor\u001b[0m\n",
      "\u001b[34mDownloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf<=3.20.0,>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from paddlepaddle-gpu) (3.18.1)\u001b[0m\n",
      "\u001b[34mCollecting opt-einsum==3.3.0\u001b[0m\n",
      "\u001b[34mDownloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from paddlepaddle-gpu) (4.4.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests>=2.20.0 in /opt/conda/lib/python3.8/site-packages (from paddlepaddle-gpu) (2.26.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.20.0->paddlepaddle-gpu) (2021.10.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests>=2.20.0->paddlepaddle-gpu) (1.26.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.20.0->paddlepaddle-gpu) (2.10)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests>=2.20.0->paddlepaddle-gpu) (2.0.4)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: paddle-bfloat, opt-einsum, astor, paddlepaddle-gpu\u001b[0m\n",
      "\u001b[34mSuccessfully installed astor-0.8.1 opt-einsum-3.3.0 paddle-bfloat-0.1.7 paddlepaddle-gpu-2.3.2\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m#033[32m[2022-09-13 08:02:23,514] [    INFO]#033[0m - Downloading resource files...#033[0m\u001b[0m\n",
      "\u001b[34m0%|          | 0/460749 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 35/460749 [00:00<31:30, 243.69it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 83/460749 [00:00<26:06, 294.10it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 131/460749 [00:00<24:45, 310.00it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 179/460749 [00:00<24:10, 317.51it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 243/460749 [00:00<21:14, 361.33it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 307/460749 [00:00<19:47, 387.60it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 387/460749 [00:01<17:26, 440.02it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 467/460749 [00:01<16:09, 474.58it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 563/460749 [00:01<14:26, 531.34it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 643/460749 [00:01<14:15, 537.53it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 755/460749 [00:01<12:37, 607.53it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 867/460749 [00:01<11:40, 656.30it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 995/460749 [00:01<10:36, 722.88it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 1123/460749 [00:02<09:56, 770.85it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 1283/460749 [00:02<08:49, 867.98it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 1443/460749 [00:02<08:09, 937.48it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 1635/460749 [00:02<07:16, 1051.36it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 1843/460749 [00:02<06:34, 1163.91it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 2051/460749 [00:02<06:05, 1254.14it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 2211/460749 [00:02<05:45, 1328.64it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 2467/460749 [00:03<05:12, 1466.56it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 2755/460749 [00:03<04:41, 1626.78it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 3075/460749 [00:03<04:14, 1801.13it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 3411/460749 [00:03<03:53, 1955.19it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 3779/460749 [00:03<03:34, 2130.82it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 4195/460749 [00:03<03:14, 2347.90it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 4653/460749 [00:03<02:39, 2859.26it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 4995/460749 [00:03<02:48, 2704.92it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 5523/460749 [00:04<02:29, 3035.93it/s]\u001b[0m\n",
      "\u001b[34m1%|▏         | 5939/460749 [00:04<02:18, 3277.11it/s]\u001b[0m\n",
      "\u001b[34m1%|▏         | 6563/460749 [00:04<02:04, 3659.90it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 7043/460749 [00:04<01:56, 3908.29it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 7738/460749 [00:04<01:36, 4697.41it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 8307/460749 [00:04<01:40, 4515.76it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 8915/460749 [00:04<01:32, 4871.20it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 9642/460749 [00:04<01:21, 5515.81it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 10467/460749 [00:05<01:19, 5699.37it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 11171/460749 [00:05<01:15, 5994.34it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 12003/460749 [00:05<01:07, 6623.96it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 12979/460749 [00:05<00:59, 7501.70it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 13891/460749 [00:05<01:02, 7137.63it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 14923/460749 [00:05<00:55, 7989.81it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 16022/460749 [00:05<00:50, 8820.03it/s]\u001b[0m\n",
      "\u001b[34m4%|▎         | 17171/460749 [00:05<00:51, 8600.78it/s]\u001b[0m\n",
      "\u001b[34m4%|▍         | 18371/460749 [00:05<00:46, 9502.53it/s]\u001b[0m\n",
      "\u001b[34m4%|▍         | 19705/460749 [00:06<00:41, 10560.40it/s]\u001b[0m\n",
      "\u001b[34m5%|▍         | 21123/460749 [00:06<00:42, 10367.68it/s]\u001b[0m\n",
      "\u001b[34m5%|▍         | 22627/460749 [00:06<00:37, 11607.36it/s]\u001b[0m\n",
      "\u001b[34m5%|▌         | 24195/460749 [00:06<00:34, 12703.52it/s]\u001b[0m\n",
      "\u001b[34m6%|▌         | 25887/460749 [00:06<00:31, 13890.86it/s]\u001b[0m\n",
      "\u001b[34m6%|▌         | 27411/460749 [00:06<00:33, 12882.68it/s]\u001b[0m\n",
      "\u001b[34m6%|▋         | 29174/460749 [00:06<00:30, 14164.12it/s]\u001b[0m\n",
      "\u001b[34m7%|▋         | 31104/460749 [00:06<00:27, 15593.30it/s]\u001b[0m\n",
      "\u001b[34m7%|▋         | 33083/460749 [00:06<00:25, 16787.13it/s]\u001b[0m\n",
      "\u001b[34m8%|▊         | 35139/460749 [00:07<00:26, 16140.41it/s]\u001b[0m\n",
      "\u001b[34m8%|▊         | 37203/460749 [00:07<00:24, 17345.44it/s]\u001b[0m\n",
      "\u001b[34m9%|▊         | 39503/460749 [00:07<00:22, 18924.55it/s]\u001b[0m\n",
      "\u001b[34m9%|▉         | 41893/460749 [00:07<00:20, 20342.55it/s]\u001b[0m\n",
      "\u001b[34m10%|▉         | 44353/460749 [00:07<00:19, 21574.82it/s]\u001b[0m\n",
      "\u001b[34m10%|█         | 46953/460749 [00:07<00:18, 22869.37it/s]\u001b[0m\n",
      "\u001b[34m11%|█         | 49507/460749 [00:07<00:19, 21464.37it/s]\u001b[0m\n",
      "\u001b[34m11%|█▏        | 52226/460749 [00:07<00:17, 23046.98it/s]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 55123/460749 [00:07<00:16, 24723.10it/s]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 58104/460749 [00:07<00:15, 26186.17it/s]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 61205/460749 [00:08<00:14, 27591.53it/s]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 64515/460749 [00:08<00:13, 29209.62it/s]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 67867/460749 [00:08<00:12, 30484.22it/s]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 71363/460749 [00:08<00:13, 29467.95it/s]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 74819/460749 [00:08<00:12, 30838.10it/s]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 78450/460749 [00:08<00:11, 32407.35it/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 82211/460749 [00:08<00:11, 33913.17it/s]\u001b[0m\n",
      "\u001b[34m19%|█▊        | 86265/460749 [00:08<00:10, 35857.05it/s]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 90411/460749 [00:08<00:09, 37511.12it/s]\u001b[0m\n",
      "\u001b[34m21%|██        | 94787/460749 [00:09<00:09, 39363.14it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 99251/460749 [00:09<00:08, 40933.64it/s]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 103913/460749 [00:09<00:08, 42630.09it/s]\u001b[0m\n",
      "\u001b[34m24%|██▎       | 108820/460749 [00:09<00:07, 44554.47it/s]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 113974/460749 [00:09<00:07, 46643.99it/s]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 119107/460749 [00:09<00:07, 45623.74it/s]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 124327/460749 [00:09<00:07, 47522.96it/s]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 129821/460749 [00:09<00:06, 49689.50it/s]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 135555/460749 [00:09<00:06, 51939.96it/s]\u001b[0m\n",
      "\u001b[34m31%|███       | 140963/460749 [00:09<00:06, 52404.49it/s]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 146597/460749 [00:10<00:05, 53570.40it/s]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 152243/460749 [00:10<00:05, 54428.46it/s]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 157950/460749 [00:10<00:05, 55215.66it/s]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 163672/460749 [00:10<00:05, 55812.91it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 169519/460749 [00:10<00:05, 56607.40it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 175347/460749 [00:10<00:05, 54017.88it/s]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 181249/460749 [00:10<00:05, 55456.77it/s]\u001b[0m\n",
      "\u001b[34m41%|████      | 187090/460749 [00:10<00:04, 56317.37it/s]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 193054/460749 [00:10<00:04, 57294.20it/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 199057/460749 [00:10<00:04, 58102.36it/s]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 204881/460749 [00:11<00:04, 58063.12it/s]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 210855/460749 [00:11<00:04, 58561.93it/s]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 216802/460749 [00:11<00:04, 58832.27it/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 222793/460749 [00:11<00:04, 59153.97it/s]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 228712/460749 [00:11<00:03, 59044.23it/s]\u001b[0m\n",
      "\u001b[34m51%|█████     | 234691/460749 [00:11<00:04, 55872.06it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 240728/460749 [00:11<00:03, 57162.50it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▎    | 246519/460749 [00:11<00:03, 57377.80it/s]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 252475/460749 [00:11<00:03, 58017.72it/s]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 258377/460749 [00:11<00:03, 58313.26it/s]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 264222/460749 [00:12<00:03, 57945.44it/s]\u001b[0m\n",
      "\u001b[34m59%|█████▊    | 270139/460749 [00:12<00:03, 58307.15it/s]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 276018/460749 [00:12<00:03, 58448.31it/s]\u001b[0m\n",
      "\u001b[34m61%|██████    | 281971/460749 [00:12<00:03, 58767.95it/s]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 287852/460749 [00:12<00:02, 58677.40it/s]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 293805/460749 [00:12<00:02, 58931.14it/s]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 299701/460749 [00:12<00:02, 55730.76it/s]\u001b[0m\n",
      "\u001b[34m66%|██████▋   | 305613/460749 [00:12<00:02, 56704.89it/s]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 311497/460749 [00:12<00:02, 57326.27it/s]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 317459/460749 [00:12<00:02, 57999.77it/s]\u001b[0m\n",
      "\u001b[34m70%|███████   | 323349/460749 [00:13<00:02, 58265.60it/s]\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 329189/460749 [00:13<00:02, 57811.85it/s]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 334980/460749 [00:13<00:02, 57407.74it/s]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 340995/460749 [00:13<00:02, 58217.29it/s]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 346823/460749 [00:13<00:01, 58041.06it/s]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 352632/460749 [00:13<00:02, 53297.93it/s]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 358291/460749 [00:13<00:01, 53775.53it/s]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 364140/460749 [00:13<00:01, 55115.14it/s]\u001b[0m\n",
      "\u001b[34m80%|████████  | 369724/460749 [00:13<00:01, 55324.51it/s]\u001b[0m\n",
      "\u001b[34m81%|████████▏ | 375347/460749 [00:14<00:01, 53138.82it/s]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 381200/460749 [00:14<00:01, 54675.98it/s]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 387041/460749 [00:14<00:01, 55756.25it/s]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 392771/460749 [00:14<00:01, 56204.70it/s]\u001b[0m\n",
      "\u001b[34m86%|████████▋ | 398413/460749 [00:14<00:01, 56056.53it/s]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 404034/460749 [00:14<00:01, 50440.41it/s]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 409777/460749 [00:14<00:00, 52363.33it/s]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 415110/460749 [00:14<00:00, 52251.28it/s]\u001b[0m\n",
      "\u001b[34m91%|█████████▏| 420769/460749 [00:14<00:00, 53490.38it/s]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 426171/460749 [00:14<00:00, 52781.17it/s]\u001b[0m\n",
      "\u001b[34m94%|█████████▎| 431774/460749 [00:15<00:00, 53721.67it/s]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 437635/460749 [00:15<00:00, 55149.71it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▋| 443510/460749 [00:15<00:00, 56209.98it/s]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 449443/460749 [00:15<00:00, 57132.91it/s]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 455171/460749 [00:15<00:00, 54445.38it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 460749/460749 [00:15<00:00, 29509.26it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 0/1 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 1/1 [00:00<00:00, 1190.21it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 0/183 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 35/183 [00:00<00:00, 249.96it/s]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 83/183 [00:00<00:00, 303.94it/s]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 131/183 [00:00<00:00, 321.49it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 183/183 [00:00<00:00, 390.04it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 0/1 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 1/1 [00:00<00:00, 1339.18it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 0/1 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 1/1 [00:00<00:00, 880.79it/s]\u001b[0m\n",
      "\u001b[34m#033[32m[2022-09-13 08:02:40,981] [    INFO]#033[0m - We are using <class 'paddlenlp.transformers.ernie.tokenizer.ErnieTokenizer'> to load 'uie-base'.#033[0m\u001b[0m\n",
      "\u001b[34mW0913 08:02:41.004599    52 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 11.6, Runtime API Version: 10.2\u001b[0m\n",
      "\u001b[34mW0913 08:02:41.025142    52 gpu_resources.cc:91] device: 0, cuDNN Version: 8.0.\u001b[0m\n",
      "\u001b[34m#033[32m[2022-09-13 08:03:09,024] [    INFO]#033[0m - global step 10, epoch: 5, loss: 0.00241, speed: 0.40 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-09-13 08:03:17,189] [    INFO]#033[0m - global step 20, epoch: 10, loss: 0.00183, speed: 1.22 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-09-13 08:03:25,475] [    INFO]#033[0m - global step 30, epoch: 15, loss: 0.00142, speed: 1.21 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-09-13 08:03:33,804] [    INFO]#033[0m - global step 40, epoch: 20, loss: 0.00115, speed: 1.20 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-09-13 08:03:42,215] [    INFO]#033[0m - global step 50, epoch: 25, loss: 0.00096, speed: 1.19 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-09-13 08:03:50,766] [    INFO]#033[0m - global step 60, epoch: 30, loss: 0.00081, speed: 1.17 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-09-13 08:03:59,418] [    INFO]#033[0m - global step 70, epoch: 35, loss: 0.00071, speed: 1.16 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-09-13 08:04:08,125] [    INFO]#033[0m - global step 80, epoch: 40, loss: 0.00062, speed: 1.15 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-09-13 08:04:16,864] [    INFO]#033[0m - global step 90, epoch: 45, loss: 0.00056, speed: 1.14 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-09-13 08:04:25,762] [    INFO]#033[0m - global step 100, epoch: 50, loss: 0.00050, speed: 1.12 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-09-13 08:04:26,560] [    INFO]#033[0m - tokenizer config file saved in /opt/ml/model/model_100/tokenizer_config.json#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-09-13 08:04:26,560] [    INFO]#033[0m - Special tokens file saved in /opt/ml/model/model_100/special_tokens_map.json#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-09-13 08:04:32,100] [    INFO]#033[0m - Evaluation precision: 0.93478, recall: 0.89583, F1: 0.91489#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-09-13 08:04:32,100] [    INFO]#033[0m - best F1 performence has been updated: 0.00000 --> 0.91489#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-09-13 08:04:32,892] [    INFO]#033[0m - tokenizer config file saved in /opt/ml/model/model_best/tokenizer_config.json#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-09-13 08:04:32,893] [    INFO]#033[0m - Special tokens file saved in /opt/ml/model/model_best/special_tokens_map.json#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-09-13 08:04:41,834] [    INFO]#033[0m - global step 110, epoch: 55, loss: 0.00046, speed: 1.12 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-09-13 08:04:50,936] [    INFO]#033[0m - global step 120, epoch: 60, loss: 0.00042, speed: 1.10 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-09-13 08:05:00,190] [    INFO]#033[0m - global step 130, epoch: 65, loss: 0.00039, speed: 1.08 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-09-13 08:05:09,599] [    INFO]#033[0m - global step 140, epoch: 70, loss: 0.00036, speed: 1.06 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-09-13 08:05:19,163] [    INFO]#033[0m - global step 150, epoch: 75, loss: 0.00034, speed: 1.05 step/s#033[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "estimator.fit(inputs, job_name = job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2b001d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dir ='../../../all-in-one-ai-sample-data/paddlenlp/inference/sample'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "10ef3ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "files = [f for f in listdir(sample_dir) if isfile(join(sample_dir, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "258d7e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs  = open(join(sample_dir, files[0]), 'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7e8dbec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_job_name = estimator.latest_training_job.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "806d6f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = None\n",
    "model_data='s3://{}/{}/output/model.tar.gz'.format(bucket, training_job_name)\n",
    "entry_point = 'inference.py'\n",
    "framework_version = '1.9.0'\n",
    "py_version = 'py38'\n",
    "model_environment = {'schema': '[\"出发地\", \"目的地\", \"费用\", \"时间\"]'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c6ba012e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PyTorchModel(\n",
    "    name = model_name,\n",
    "    model_data = model_data,\n",
    "    entry_point = entry_point,\n",
    "    source_dir = source_dir,\n",
    "    role = role,\n",
    "    framework_version = framework_version, \n",
    "    py_version = py_version,\n",
    "    env = model_environment\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "91ba9030",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = None\n",
    "instance_type = 'ml.m5.xlarge'\n",
    "instance_count = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d125c6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------!"
     ]
    }
   ],
   "source": [
    "predictor = model.deploy(\n",
    "    endpoint_name = endpoint_name,\n",
    "    instance_type = instance_type, \n",
    "    initial_instance_count = instance_count\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "151e454d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'result': [{'出发地': [{'text': '上海',\n",
       "     'start': 0,\n",
       "     'end': 2,\n",
       "     'probability': 0.979479968547821}],\n",
       "   '目的地': [{'text': '杭州',\n",
       "     'start': 7,\n",
       "     'end': 9,\n",
       "     'probability': 0.9992395639419556}],\n",
       "   '费用': [{'text': '73',\n",
       "     'start': 20,\n",
       "     'end': 22,\n",
       "     'probability': 0.560113251209259}],\n",
       "   '时间': [{'text': '9月24日',\n",
       "     'start': 12,\n",
       "     'end': 17,\n",
       "     'probability': 0.999651312828064}]}]}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "predictor.serializer = JSONSerializer()\n",
    "predictor.deserializer = JSONDeserializer()\n",
    "\n",
    "predictor.predict(\n",
    "    {\"inputs\":\"上海虹桥高铁到杭州时间是9月24日费用是73元\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b379b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
