{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e0e46fa-ceb9-4cb9-a303-bf86cfd61fa6",
   "metadata": {},
   "source": [
    "## Run WeNet on SageMaker - Gigaspeech"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8999ae83",
   "metadata": {},
   "source": [
    "### 选择Notebook环境\n",
    "Notebook的运行环境可以选择conda_pytorch_p38。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6548ae60-4acc-458a-aa27-e39cf5ff6455",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 下载 wenet 代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de59713-f325-4946-9f13-f67e5780b470",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ~/SageMaker\n",
    "\n",
    "!git clone https://github.com/Chen188/wenet -b sagemaker-giga\n",
    "\n",
    "wenet_src = '~/SageMaker/wenet'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a3c37d-73eb-4c67-84da-c1225e1d13a0",
   "metadata": {},
   "source": [
    "### 获取基本环境信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7474ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "print('SageMaker version: ', sagemaker.__version__)\n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "region = boto3.session.Session().region_name\n",
    "role   = get_execution_role()\n",
    "sess   = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "\n",
    "bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afb2cad",
   "metadata": {},
   "source": [
    "## 准备Docker image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b360a916",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecr_repository = 'sagemaker-wenet'\n",
    "\n",
    "# 登录ECR服务\n",
    "!aws ecr get-login-password --region {region} | docker login --username AWS --password-stdin {account_id}.dkr.ecr.{region}.amazonaws.com.cn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbb9d56",
   "metadata": {},
   "source": [
    "### 创建容器注册表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a81b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws ecr create-repository --repository-name $ecr_repository"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3e9b46",
   "metadata": {},
   "source": [
    "### 构建训练镜像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade357c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_docker_file_path = '~/SageMaker/wenet'\n",
    "\n",
    "!cat $training_docker_file_path/Dockerfile.gigaspeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d22377",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 构建训练镜像并推送到ECR, China Region.\n",
    "tag = ':training-pip-pt_1_10_0'\n",
    "training_repository_uri = '{}.dkr.ecr.{}.amazonaws.com.cn/{}'.format(account_id, region, ecr_repository + tag)\n",
    "print('training_repository_uri: ', training_repository_uri)\n",
    "\n",
    "!cd $training_docker_file_path && docker build -t \"$ecr_repository$tag\" . -f Dockerfile.gigaspeech\n",
    "!docker tag {ecr_repository + tag} $training_repository_uri\n",
    "!docker push $training_repository_uri\n",
    "\n",
    "# !docker pull $training_repository_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77a9fb5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 训练数据准备"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c9ea80-8867-4089-88ab-e86f688bc238",
   "metadata": {},
   "source": [
    "### 挂载共享存储\n",
    "\n",
    "可以使用EFS或者FSx for Lustre。这里我们使用的是EFS，然后挂载到/efs目录。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c33685b-cf00-4e2e-8c78-0935f92d2e02",
   "metadata": {},
   "source": [
    "### run.sh 中的变量定义，及完成Stage 0 - 4 之后的结构\n",
    "\n",
    "set: giga数据集，有XS|M|L|XL 等\n",
    "\n",
    "giga_data_dir: 下载好的 giga open data （Stage 0）\n",
    "```\n",
    "├── audio\n",
    "│   ├── audiobook\n",
    "│   ├── podcast\n",
    "│   └── youtube\n",
    "├── dir_structure\n",
    "├── files.yaml\n",
    "├── GigaSpeech.json\n",
    "├── GigaSpeech.json.gz\n",
    "├── GigaSpeech.json.gz.aes\n",
    "└── TERMS_OF_ACCESS\n",
    "```\n",
    "data: 数据预处理后的保存目录（Stage 0，1，2）\n",
    "```\n",
    "├── corpus\n",
    "│   ├── dev_utt_list\n",
    "│   ├── reco2dur\n",
    "│   ├── segments\n",
    "│   ├── test_utt_list\n",
    "│   ├── text\n",
    "│   ├── train_xs_utt_list\n",
    "│   ├── utt2dur\n",
    "│   ├── utt2subsets\n",
    "│   └── wav.scp\n",
    "├── dev\n",
    "│   ├── data.list\n",
    "│   ├── segments\n",
    "│   ├── spk2utt\n",
    "    ....\n",
    "├── lang_char_XS\n",
    "│   ├── input.txt\n",
    "│   ├── train_xs_unigram5000.model\n",
    "│   ├── train_xs_unigram5000_units.txt\n",
    "│   └── train_xs_unigram5000.vocab\n",
    "├── test\n",
    "│   ├── data.list\n",
    "    ....\n",
    "└── train_xs\n",
    "    ├── data.list\n",
    "    ....\n",
    "```\n",
    "\n",
    "shards_dir: shard 后的数据（Stage 3）\n",
    "```\n",
    "├── dev\n",
    "│   ├── shards_000000000.tar\n",
    "    ...\n",
    "├── test\n",
    "│   ├── shards_000000000.tar\n",
    "    ...\n",
    "└── train_xs\n",
    "    ├── shards_000000000.tar\n",
    "    ...\n",
    "```\n",
    "\n",
    "dir: 实验目录，包含 ddp_init(分布式) 及 模型文件\n",
    "```\n",
    "├── init.pt\n",
    "├── init.yaml\n",
    "├── init.zip\n",
    "└── train.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b798f6c",
   "metadata": {},
   "source": [
    "### 数据下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2b3a63-4215-4a5e-856c-26a0b096ffa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装依赖\n",
    "!pip install speechcolab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c59239",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root     = \"/efs/wenet-data\"\n",
    "data_set      = \"XS\"\n",
    "\n",
    "giga_data_dir = f\"{data_root}/giga/raw-data\"\n",
    "processed_dir = f\"{data_root}/giga/processed\"\n",
    "shards_dir    = f\"{data_root}/giga/shards\"\n",
    "expr_dir      = f\"{data_root}/expr/giga\"\n",
    "\n",
    "!mkdir -p \"$giga_data_dir\" \"$processed_dir\" \"$shards_dir\" \"$expr_dir\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484262fa-0069-4956-a819-018e9ddec413",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo '!!!!APPLY FOR DOWNLOAD CREDENTIALS BEFORE RUNNING BELLOW CODE, CHECK GigaSpeech/README.md!!!'\n",
    "!echo '!!!!APPLY FOR DOWNLOAD CREDENTIALS BEFORE RUNNING BELLOW CODE, CHECK GigaSpeech/README.md!!!'\n",
    "!echo '!!!!APPLY FOR DOWNLOAD CREDENTIALS BEFORE RUNNING BELLOW CODE, CHECK GigaSpeech/README.md!!!'\n",
    "\n",
    "# subset(default {XL}) specifies the subset to download\n",
    "set = '{' + data_set + '}'\n",
    "\n",
    "%cd ~/SageMaker\n",
    "!git clone https://github.com/SpeechColab/GigaSpeech \n",
    "\n",
    "%cd GigaSpeech\n",
    "!echo 'replace-with-your-password' > SAFEBOX/password\n",
    "\n",
    "!bash utils/download_gigaspeech.sh  --subset {set} --host magicdata {giga_data_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79138148",
   "metadata": {},
   "source": [
    "### 数据预处理\n",
    "\n",
    "原始数据存放在`$giga_data_dir`中，预处理后的数据放在`$processed_dir`，分片后的数据放在 `shards_dir`。\n",
    "\n",
    "由于默认使用的是XS数据集，可能遇到 `Warning: POD0000000501 something is wrong, maybeAssertionError, skipped` 的提示，可以忽略掉。\n",
    "\n",
    "数据处理时间较长，需要耐心等待。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da749a72",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%cd ~/SageMaker/wenet\n",
    "\n",
    "from sagemaker.pytorch.estimator import PyTorch\n",
    "\n",
    "CUDA_VISIBLE_DEVICES    = '0'\n",
    "\n",
    "instance_count   = 1\n",
    "instance_type    = 'local'\n",
    "\n",
    "sm_data_root     = '/opt/ml/input/data'\n",
    "\n",
    "sm_giga_data_dir = f\"{sm_data_root}/raw-data\"\n",
    "sm_processed_dir = f\"{sm_data_root}/processed\"\n",
    "sm_trail_dir     = f\"{sm_data_root}/trial\"\n",
    "sm_shards_dir    = f\"{sm_data_root}/shards\"\n",
    "\n",
    "hp= {\n",
    "    'stage': 0, 'stop_stage': 3, 'set': data_set, \n",
    "    'data': sm_processed_dir,\n",
    "    'dir':  sm_trail_dir,\n",
    "    'giga_data_dir': sm_giga_data_dir,\n",
    "    'shards_dir':    sm_shards_dir,\n",
    "    'num_nodes':     instance_count,\n",
    "    'CUDA_VISIBLE_DEVICES': CUDA_VISIBLE_DEVICES\n",
    "}\n",
    "\n",
    "estimator=PyTorch(\n",
    "    entry_point     = 'examples/gigaspeech/s0/sm-run.sh',\n",
    "    image_uri       = 'sagemaker-wenet:training-pip-pt_1_10_0',\n",
    "    instance_type   = instance_type,\n",
    "    instance_count  = instance_count,\n",
    "    source_dir      = '.',\n",
    "    role            = role,\n",
    "    hyperparameters = hp,\n",
    "    \n",
    "    disable_profiler     = True,\n",
    "    debugger_hook_config = False\n",
    ")\n",
    "\n",
    "estimator.fit({\n",
    "    'raw-data':  f\"file://{giga_data_dir}\",\n",
    "    'processed': f\"file://{processed_dir}\",\n",
    "    'shards':    f\"file://{shards_dir}\",\n",
    "    'trial':     f\"file://{expr_dir}\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66191ae5",
   "metadata": {},
   "source": [
    "## 模型训练 - 本地训练模式\n",
    "\n",
    "在模型研发过程中，算法人员需要反复调整代码逻辑，如果每次代码调整就打包一个docker镜像就显得很麻烦，因此，您可以先通过SageMaker的本地训练模式，来调试代码。本地训练模式会直接在Notebook所在实例中启动对应的容器并执行训练逻辑，并自动将数据映射给容器。\n",
    "\n",
    "CUDA_VISIBLE_DEVICES需要和之行数据处理代码实例的GPU相匹配，如单个实例只有两个GPU卡，则设为'0,1'。\n",
    "\n",
    "**Open terminal and run follow command with ROOT user**\n",
    "\n",
    "```bash\n",
    "docker_daemon_file=/etc/docker/daemon.json\n",
    "echo Origin content: `cat $docker_daemon_file`\n",
    "\n",
    "echo '{ \n",
    "   \"runtimes\": {\n",
    "        \"nvidia\": {\n",
    "            \"path\": \"nvidia-container-runtime\",\n",
    "            \"runtimeArgs\": []\n",
    "        }\n",
    "    },\n",
    "    \"default-shm-size\": \"14G\"\n",
    "}' > /etc/docker/daemon.json\n",
    "\n",
    "cat $docker_daemon_file\n",
    "\n",
    "service docker restart\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9fba5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%cd ~/SageMaker/wenet\n",
    "\n",
    "from sagemaker.pytorch.estimator import PyTorch\n",
    "\n",
    "CUDA_VISIBLE_DEVICES    = '0'\n",
    "\n",
    "instance_count   = 1\n",
    "instance_type    = 'local_gpu'\n",
    "\n",
    "sm_data_root     = '/opt/ml/input/data'\n",
    "\n",
    "sm_giga_data_dir = f\"{sm_data_root}/raw-data\"\n",
    "sm_processed_dir = f\"{sm_data_root}/processed\"\n",
    "sm_trail_dir     = f\"{sm_data_root}/trial\"\n",
    "sm_shards_dir    = f\"{sm_data_root}/shards\"\n",
    "\n",
    "hp= {\n",
    "    'stage': 4, 'stop_stage': 4, 'set': data_set, \n",
    "    'data': sm_processed_dir,\n",
    "    'dir':  sm_trail_dir,\n",
    "    'giga_data_dir': sm_giga_data_dir,\n",
    "    'shards_dir':    sm_shards_dir,\n",
    "    'num_nodes':     instance_count,\n",
    "    'CUDA_VISIBLE_DEVICES': CUDA_VISIBLE_DEVICES\n",
    "}\n",
    "\n",
    "estimator=PyTorch(\n",
    "    entry_point     = 'examples/gigaspeech/s0/sm-run.sh',\n",
    "    image_uri       = 'sagemaker-wenet:training-pip-pt_1_10_0',\n",
    "    instance_type   = instance_type,\n",
    "    instance_count  = instance_count,\n",
    "    source_dir      = '.',\n",
    "    role            = role,\n",
    "    hyperparameters = hp,\n",
    "    \n",
    "    disable_profiler     = True,\n",
    "    debugger_hook_config = False\n",
    ")\n",
    "\n",
    "estimator.fit({\n",
    "    'raw-data':  f\"file://{giga_data_dir}\",\n",
    "    'processed': f\"file://{processed_dir}\",\n",
    "    'shards':    f\"file://{shards_dir}\",\n",
    "    'trial':     f\"file://{expr_dir}\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2585285",
   "metadata": {},
   "source": [
    "## 模型训练 - SageMaker托管实例\n",
    "\n",
    "在确定代码逻辑无误后，我们可以很容易通过修改参数的方式，使用托管的实例开启真正的训练任务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51556790",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ~/SageMaker/wenet\n",
    "\n",
    "from sagemaker.inputs import FileSystemInput\n",
    "from sagemaker.pytorch.estimator import PyTorch\n",
    "\n",
    "file_system_id = 'fs-0fafc0e57d05616b4'\n",
    "file_system_access_mode = 'rw'\n",
    "file_system_type = 'EFS'\n",
    "security_group_ids = ['sg-066097e10b3fcc47e']\n",
    "subnets= ['subnet-0d0b4cf92fba1cb2b']\n",
    "\n",
    "# 定义数据输入\n",
    "file_system_input_raw  = FileSystemInput(file_system_id=file_system_id,\n",
    "                                  file_system_type=file_system_type,\n",
    "                                  directory_path='/wenet-data/giga/raw-data',\n",
    "                                  file_system_access_mode=file_system_access_mode)\n",
    "\n",
    "file_system_input_proc = FileSystemInput(file_system_id=file_system_id,\n",
    "                                  file_system_type=file_system_type,\n",
    "                                  directory_path='/wenet-data/giga/processed',\n",
    "                                  file_system_access_mode=file_system_access_mode)\n",
    "\n",
    "file_system_input_shards = FileSystemInput(file_system_id=file_system_id,\n",
    "                                  file_system_type=file_system_type,\n",
    "                                  directory_path='/wenet-data/giga/shards',\n",
    "                                  file_system_access_mode=file_system_access_mode)\n",
    "\n",
    "file_system_input_expr = FileSystemInput(file_system_id=file_system_id,\n",
    "                                  file_system_type=file_system_type,\n",
    "                                  directory_path='/wenet-data/expr/giga',\n",
    "                                  file_system_access_mode=file_system_access_mode)\n",
    "\n",
    "\n",
    "training_repository_uri = training_repository_uri\n",
    "CUDA_VISIBLE_DEVICES    = '0'\n",
    "\n",
    "instance_count   = 1\n",
    "instance_type    = 'ml.g4dn.xlarge'\n",
    "\n",
    "sm_data_root     = '/opt/ml/input/data'\n",
    "\n",
    "sm_giga_data_dir = f\"{sm_data_root}/raw-data\"\n",
    "sm_processed_dir = f\"{sm_data_root}/processed\"\n",
    "sm_trail_dir     = f\"{sm_data_root}/trial\"\n",
    "sm_shards_dir    = f\"{sm_data_root}/shards\"\n",
    "\n",
    "hp= {\n",
    "    'stage': 4, 'stop_stage': 4, 'set': data_set, \n",
    "    'data': sm_processed_dir,\n",
    "    'dir':  sm_trail_dir,\n",
    "    'giga_data_dir': sm_giga_data_dir,\n",
    "    'shards_dir':    sm_shards_dir,\n",
    "    'num_nodes':     instance_count,\n",
    "    'CUDA_VISIBLE_DEVICES': CUDA_VISIBLE_DEVICES\n",
    "}\n",
    "\n",
    "estimator=PyTorch(\n",
    "    entry_point     = 'examples/gigaspeech/s0/sm-run.sh',\n",
    "    image_uri       = training_repository_uri,\n",
    "    instance_type   = instance_type,\n",
    "    instance_count  = instance_count,\n",
    "    source_dir      = '.',\n",
    "    role            = role,\n",
    "    hyperparameters = hp,\n",
    "    \n",
    "    subnets         = subnets,\n",
    "    security_group_ids   = security_group_ids,\n",
    "    \n",
    "    disable_profiler     = True,\n",
    "    debugger_hook_config = False\n",
    ")\n",
    "\n",
    "estimator.fit({\n",
    "    'raw-data':  file_system_input_raw,\n",
    "    'processed': file_system_input_proc,\n",
    "    'shards':    file_system_input_shards,\n",
    "    'trial':     file_system_input_expr\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
