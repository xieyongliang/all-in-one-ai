{
  "header": "All-In-One AI",
  "home": {
    "title": "All-In-One AI soluton guidance",
    "about": "About this soluton guidance",
    "about_content": "This solution includes AI/ML models suitable for specific business scenarios, such as object detection, image classification, text recognition, object extraction/generation, text summarization, intent recognition, knowledge graph, time series prediction, etc. It can be widely used in manufacturing, Maintenance, enterprise safety production, content production, document identification, comment identification, short video content understanding and generation, personalized recommendation, advertisement placement, sales forecast and other scenarios. The solution includes basic functions such as cloud data annotation, model training, deployment, and reasoning commonly used in AI/ML processes, enabling the entire process to achieve low threshold, full functionality, visualization, and customization. Even if you do not have a deep understanding of AI/ML, you can complete the entire AI/ML process through a graphical interface to solve business problems in specific business scenarios. The solution can further export AI/ML models for these specific business scenarios, provide complete source code, demo websites, and automated deployment methods that can be used directly or further customized to help you accelerate the entire AI/ML implementation process and bring more The business load is shifted to the cloud.",
    "architecture": "Architecture",
    "architecture_components": "Components",
    "architecture_component_load_balaner": "Use Amazon Application Load Balancer to distribute traffic to backend web servers",
    "architecture_component_ecs": "Use Amazon ECS to host your web server ",
    "architecture_component_api_gateway": "Use Amazon API Gateway to proxy various HTTP/WebSocket requests",
    "architecture_compoent_lambda": "Use Amazon Lambda to implement backend functions of various web servers",    
    "architecture_component_sagemaker": "Use Amazon SageMaker for AI/ML model training, deployment, and inference",
    "architecture_component_greengrass": "Management of IoT core devices/thing groups, components, deployments using Amazon Greegrass",
    "architecture_component_iam": "Use Amazon IAM to manage access to resources",
    "architecture_component_vpc": "Use Amazon VPC to divide and isolate network usage, put various resources in private subnets as much as possible, and access resources on Amazon cloud technology through VPC endpoint/interface endpoint",
    "architecture_component_s3": "Use Amazon S3 to save various data, model files, etc. of AI/ML models",
    "architecture_component_efs": "Use Amazon EFS to expand temporary storage for Amazon Lambda",
    "architecture_component_dynamodb": "Use Amazon DynamodDB to save various metadata",
    "architecture_component_sqs": "Use Amazon SQS to decouple upstream and downstream asynchronous data processing",
    "architecture_component_opensearch": "Use Amazon OpenSearch to save annotation results and implement KNN to search for graphs",
    "architecture_component_cloudwatch": "Use Amazon CloudWatch to monitor resources and applications",
    "architecture_component_cloudformation": "Use Amazon CloudFormation to create and manage resources using templates",
    "architecture_component_cognito": "Use Amazon Cognito to implement user identity management and authentication",
    "advantanges": "Advantanges",
    "advantange_muliple_industrial_models": "Multiple industrial models and visualized demonstrations supported",
    "advantange_muliple_industrial_models_content": "Multiple industrial models are already supported, including track maintenance, PPE detection, image classification, image search, document recognition, receipt recognition, generic object detection, customer sentiment analysis, summary generation, text labeling, entity and relationship extraction from documents, etc., Demonstrate real-time inference or run batch inference tasks in an intuitive way",
    "advantange_muliple_industrial_algorithms": "Multiple machine learning algorithms supported",
    "advantange_muliple_industrial_algorithms_content": "A variety of machine learning algorithms have been supported, including object detection, image classification, OCR/table recognition, text summarization, text classification, named entity/relationship recognition, fine-grained sentiment analysis, etc. You can use your own based on the supported algorithms Data on demand to customize industrial models.",
    "fully_machine_learning_process_support": "Complete machine learning process supported",
    "fully_machine_learning_process_support_content": "Supports multiple machine learning tasks such as labeling, training, cloud/edge deployment, real-time reasoning, batch reasoning, pipeline, etc., provides comprehensive API support to facilitate customized development, provides various sample codes, and provides deployment scripts to realize automatic deployment in global regions.",
    "official_website": "Solution guidance official website"
  },
  "app_layout": {
    "scenarios": "Scenarios",
    "industrial_models": "Industrial models",
    "algorithms": "Algorithms",
    "overview": "Overview",
    "home": "Home",
    "train_task_success": "Train task was started successfly",
    "train_task_info": "Train task is in progress",
    "train_task_error": "Train task was failed to start",
    "deploy_task_success": "Deploy task was started successfly",
    "deploy_task_info": "Deploy task is in progress",
    "deploy_task_error": "Deploy task was failed to start",
    "pipeline_task_success": "Pipeline task was started successfly",
    "pipeline_task_info": "Pipeline task is in progress",
    "pipeline_task_error": "Pipeline task was failed to start"
  },
  "scenarios": {
    "ppe": {
      "title": "PPE solution guiance",
      "about_content": "Personal protective equipment, commonly referred to as 'PPE', is equipment worn to minimize exposure to hazards that cause serious workplace injuries and illnesses. These injuries and illnesses may result from contact with chemical, radiological, physical, electrical, mechanical, or other workplace hazards. Personal protective equipment may include items such as gloves, safety glasses and shoes, earplugs or muffs, hard hats, respirators, or coveralls, vests and full body suits.",
      "features_content": "A suite of PPE Detector hardware + AI + 3rd party service solutions. It aims to transform the existing physical assets of manufacturing enterprises into smart assets. For example, there are many IP camera system. These cameras are primarily used to record video capabilities in fixed physical areas and do not have the ability to actively monitor, for example, whether workers are wearing safety helmets correctly. Using the out-of-the-box AI kit, you can connect these IP cameras to the kit, and the AI model in the kit can identify the worker's helmet wearing in the video in real time. Once sent If you violate the rules (without wearing a helmet), an alarm message will be automatically sent to the manager's corporate WeChat, and picture evidence will be provided. "
    },
    "track": {
      "title": "Track maintenance solution guidance",
      "about_content": "Cameras installed on train underframe to detect crack running on East Rail Line(EAL). Photos captured by cameras will be used to detect track defects.",
      "features_content": "1) Optimize the alarm data connection in AWS. 2) Alarm data sync to S3 for further data visualization development. 3) Develop ML models to meet the performance requirement. 4) Manage the whole ML pipeline include building , training and deploying through MLOps approach with continuous learning feature. 5) Web UI for showing the model result and allowing user to verify the result. "  
    },
    "about": "About solution guidance",
    "architecture": "Solution guidance architecture",
    "features": "Solution guidance features"
  },
  "industrial_models": {
    "demos": "Demo",
    "pipelines": "ML pipelines",
    "training_jobs": "Training jobs",
    "models": "Models",
    "endpoints": "Endpoints",
    "deploys": "Deploys",
    "transform_jobs": "Transform jobs",
    "rest_apis": "Rest APIs",
    "greengrass_components": "Greengrass components",
    "greengrass_deployments": "Greengrass deployments",
    "common": {
      "submit": "Submit",
      "cancel": "Cancel",
      "key": "Key",
      "value": "Value",
      "actions": "Actions",
      "create": "Create",
      "remove": "Remove",
      "refresh": "Refresh",
      "stop": "Stop",
      "review": "Review",
      "edit": "Edit",
      "delete": "Delete",
      "attach": "Attach",
      "detach": "Detach",
      "add_or_edit_tags": "Add/Edit tags",
      "container": "Container",
      "days": "Days",
      "hours": "Hours",
      "minutes": "Minutes",
      "seconds": "Seconds",
      "tags": "Tags - optional",
      "add_tag": "Add tag",
      "show_all": "Show all",
      "status": "Status",
      "duration": "Duration",
      "error_occured": "'Error occured, please check the output of Browser dev tools and try it again'",
      "name": "Name",
      "version": "Version",
      "creation_time": "Creation time",
      "last_modified_time": "Last modified time",
      "billable_time_in_seconds": "Billable time (seconds)",
      "uri": "URI",
      "function": "Function",
      "choose_file": "Choose file"
    },
    "overview": {
      "create_industrial_model": "Create industrial model",
      "edit_industrial_model": "Edit industrial model",
      "create_industrial_model_description": "To use an industrial model for training, deployment, and inference, please create industrial model based on supported algorithm first",
      "industrial_model_settings": "Industrial model settings",
      "industrial_model_name": "Industrial model name",
      "industrial_model_description": "Industrial model description",
      "industrial_model_algorithm": "Industrial model algorithm",
      "select_icon": "Select an icon for your industrial model",
      "algorithm_extra_and_sample_data_settings": "Algorithm specific extra information and samples settings",
      "algorithm_extra": "Paste your algorithm specific extra information here, please refer to https://docs.ai.examples.pro/developer/",
      "sample_data": "Paste your model sample data s3 uri here",
      "industrial_models_option_start_from_existing": "You can simply start from the existing industrial models.",
      "industrial_models_option_create_your_own": "You can also create your own industrial model based on the supported algorithms.",
      "create_your_own_industrial_model": "Create your own industrial model",
      "try_it": "Try it",
      "delete_industrial_model": "This will permanently delete your industrial model and cannot be undone. This may affect other resources."
    },
    "demo": {
      "demo_options": "Demo options",
      "demo_option_sample": "Realtime inference with sample data",
      "demo_option_local": "Realtime inference with local data",
      "advanced_mode": "Advanced mode",
      "select_endpoint": "Select a SageMaker endpoint",
      "select_endpoint_object_detection": "Select a SageMaker endpoint for object detection",
      "select_endpoint_text_recognition": "Select a SageMaker endpoint for text recognition",
      "select_local_image": "Select local image",
      "select_text_field": "Select text field",
      "reverse_line_color": "Reverse line color",
      "key_value_extraction": "Key/value information extraction",
      "input": "Input",
      "output": "Output",
      "data": "Data",
      "original_data": "Orignal data",
      "prediction_data": "Predicted data",
      "run": "Run",
      "sample_data": "Sample data",
      "loading": "Loading...",
      "preparing": "Preparing",
      "processing": "Processing...",
      "quick_start": "Quick start",
      "batch_annotation": "Batch annotation",
      "exit_batch_annotation": "Exit batch annotation",
      "train": "Train",
      "deploy": "Deploy",
      "sample_code": "Sample code",
      "show_sample_code": "Show sample code",
      "hide_sample_code": "Hide sample code",
      "select_function": "Select a Lambda function",
      "open_function_in_aws_console": "Open in AWS Lambda consol",
      "candidate_labels": "Candidate labels",
      "add_label": "Add label",
      "close": "Close",
      "exit": "Exit",
      "upload": "Upload",
      "zoom_in": "zoom in",
      "zoom_out": "zoom-out",
      "zoom_fit": "zoom-fit",
      "zoom_max" : "zoom-max",
      "image_drag_mode": "image drag mode",
      "turn_on_image_drag_mode": "turn on image drage mode only when image is zoomed",
      "turn_off_image_drag_mode": "turn off image drage mode",
      "cursor_cross_hair": "cursor crosshair",
      "turn_on_cursor_cross_hair": "turn on cursor crosshair",
      "turn_off_cursor_cross_hair": "turn off cursor crosshair",
      "export_annotations": "export annotations",
      "import_annotations": "import annotations",
      "import_images": "Import images",
      "import_progress": "Import progress",
      "image_search": "Search by image",
      "image_preview": "Preview image",
      "search": "Search",
      "unsupported": "unsupported demo",
      "json_parse_error": "JSON data parse error, please check it and try again",
      "unzip_error": "Unzip files error, please check it and try again",
      "file_size_over_6M": "Uploaded file size shold be equal or less than 6M",
      "image_generic": "Image rank",
      "import_with_realtimeinference": "Import with realtime inference",
      "import_with_batchtransform": "Imoport with batch transform job"
    },
    "training_job": {
      "create_training_job": "Create training job",
      "review_training_job": "Review training job",
      "create_training_job_description": "When you create a training job, Amazon SageMaker sets up the distributed compute cluster, performs the training, and deletes the cluster when training has completed. The resulting model artifacts are stored in the location you specified when you created the training job.",
      "job_settings": "Job settings",
      "job_name": "Job name",
      "job_name_hint": "Maximum of 63 alphanumeric characters. Can include hyphens (-), but not spaces. Must be unique within your account in an AWS Region.",
      "algorithm_specification": "Algorithm specification",
      "algorithm_container_options": "Use SageMaker built-in container image or your own container image.",
      "algorithm_container_option_byos": "Bring your own script with SageMaker built-in container image",
      "algorithm_container_option_byoc": "Bring your own container image",
      "resource_configuration": "Resource configuration",
      "instance_type": "Instance type",
      "instance_count": "Instance count",
      "hyperparameters": "Hyperparameters",
      "hyperparameters_description": "You can use hyperparameters to finely control training. Choose Add hyperparameter to get started.",
      "add_hyperparameter": "Add hyperparameter",
      "input_data_configuration": "Input data configuration",
      "input_data_configuration_description": "Create up to 20 channels of input sources. If the algorithm you chose supports multiple input channels, you can specify those here.",
      "additional_storage_volume_in_gb": "Additional storage volume per instance (GB)",
      "stop_condiction": "Stop condiction",
      "maximum_runtime": "Maximum runtime",
      "maximum_runtime_in_seconds": "Maximum runtime (s)",
      "checkpoint_configuration": "Checkpoint configuration - optional",
      "checkpoint_configuration_description": "The algorithm is responsible for periodically generating checkpoints. The checkpoints are saved to this location and used to resume managed spot training jobs",
      "s3_location": "S3 location",
      "local_path": "Local path - optional",
      "local_path_description": "If the algorithm provides checkpoints, this is the local location the checkpoints are written to. If you do not specify a location, the checkpoints are written to /opt/ml/checkpoints.",
      "output_data_configuration": "Output data configuration",
      "managed_spot_training": "Managed spot training",
      "enable_managed_spot_training": "Enable managed spot training - optional",
      "enable_managed_spot_training_description": "Save compute costs for jobs that have flexibility in start and end times. Amazon SageMaker will use spare capacity only to run this job.",
      "maximum_wait_time": "Maximum wait time before job terminates optional stopping condition",
      "maximum_wait_time_description": "At the end of this duration you will receive the complete or partial results of you managed spot training job.",
      "job_summary": "Job summary",
      "attach_training_job": "This will attach this training job to current industrial model.",
      "detach_training_job": "This will dettach this training job from current industrial model.",
      "stop_training_job": "This will permanently stop your training job and cannot be undone. This may affect other resources.",
      "training_job_summary": "Training job summary",
      "training_start_time": "Training start time",
      "training_end_time": "Training end time",
      "training_time_in_seconds": "Training time (seconds)",
      "training_input_mode": "TrainingInputMode",
      "training_image": "Training image",
      "channel_name": "Channel name",
      "s3_data_type": "S3 data type",
      "s3_data_distribution_type": "S3 data distribution type",
      "s3_model_artifact": "S3 model artifact"
    },
    "deploy": {
      "create_deploy": "Create deployment",
      "create_deploy_description": "To deploy a model to Amazon SageMaker, first create the model and endpoint.",
      "deploy_settings": "Deploy settings",
      "model_name": "Model name",
      "model_data": "Model data",
      "endpoint_name": "Endpoint name",
      "instance_type": "Instance type",
      "instance_count": "Instance count",
      "environments": "Environments",
      "add_environment_variable": "Add environment variable"
    },
    "model": {
      "create_model": "Create model",
      "review_model": "Review model",
      "create_model_description": "To deploy a model to Amazon SageMaker, first create the model by providing the location of the model artifacts and inference code.",
      "model_settings": "'Model settings",
      "model_name": "Model name",
      "model_name_hint": "Maximum of 63 alphanumeric characters. Can include hyphens (-), but not spaces. Must be unique within your account in an AWS Region.",
      "container_definition": "Container definition",
      "container_input_options": "Container input options",
      "container_input_option_provide_model_artifacts_and_inference_image": "Provide model artifacts and inference image location.",
      "container_input_option_select_model_package_group_resource": "Select a model package resource.",
      "container_model_options": "Provide model artifacts and inference image options",
      "container_model_option_use_single_model": "Use a single model.",
      "container_model_option_use_multiple_model": "Use multiple models.",
      "inference_code_image_location": "Location of inference code image",
      "inference_code_image_locatioon_description": "Type the registry path where the inference code image is stored in Amazon ECR.",
      "model_artifacts_location": "Location of model artifacts",
      "model_artifacts_location_description": "Type the URL where model artifacts are stored in S3.",
      "create_model_package_group": "Create a new model package group",
      "create_model_package": "Create a new model package",
      "model_packages": "Model packages",
      "model_package_group_name": "Name of model package group",
      "environments": "Environment variables - optional",
      "add_environment_variable": "Add environment variable",
      "attach_model": "This will attach this model to current industrial model.",
      "detach_model": "This will detach this model from current industrial model.",
      "delete_model": "This will permanently delete your model and cannot be undone. This may affect other resources.",
      "model_summary": "Model summary",
      "mode": "Mode",
      "container_image": "image",
      "model_data_url": "Model data location",
      "model_package_arn": "Model package arn"
    },
    "endpoint": {
      "create_endpoint": "Create endpoint",
      "review_endpoint": "Review endpoint",
      "create_endpoint_description": "To deploy models to Amazon SageMaker, first create an endpoint. Specify which models to deploy, and the relative traffic weighting and hardware requirements for each.",
      "production_variant": "Production variants",
      "model_name": "Model name",
      "instance_type": "Instance type",
      "elastic_inference": "Elastic inference",
      "initial_instance_count": "Initial instance count",
      "initial_weight": "Initial weight",
      "endpoint_settings": "Endpoint settings",
      "endpoint_name": "Endpoint name",
      "endpoint_name_description": "Your application uses this name to access this endpoint.",
      "endpoint_name_hint": "Maximum of 63 alphanumeric characters. Can include hyphens (-), but not spaces. Must be unique within your account in an AWS Region.",
      "endpoint_configuration_settings": "Endpoint configuration setttings",
      "endpoint_configuration_name": "Endpoint configuration name",
      "attach_endpoint": "This will attach this endpoint to current industrial model.",
      "detach_endpoint": "This will detach this endpoint from current industrial model.",
      "delete_endpoint": "This will permanently delete your endpoint and cannot be undone. This may affect other resources.",
      "endpoint_summary": "Endpoint summary",
      "endpoint_runtime_settings": "Endpoint runtime settings",
      "variant_name": "Variant name",
      "current_weight": "Current weight",
      "desired_weight": "Desired weight",
      "current_instance_count": "Current instance count",
      "desired_instance_count": "Desired instance count"
    },
    "transform_job": {
      "create_transform_job": "Create transform job",
      "review_transform_job": "Review transform job",
      "create_transform_job_description": "A transform job uses a model to transform data and stores the results at a specified location.",
      "job_settings": "Job settings",
      "job_name": "Job name",
      "job_name_hint": "Maximum of 63 alphanumeric characters. Can include hyphens (-), but not spaces. Must be unique within your account in an AWS Region.",
      "model_name": "Model name",
      "instance_type": "Instance type",
      "instance_count": "Instance count",
      "max_concurrent_transform": "Max concurrent transforms - optional",
      "max_concurrent_transform_description": "Maximum number of parallel requests that can be launched on a single instance.",
      "max_payload_size_in_mb": "Max payload size (MB) - optional",
      "max_payload_size_in_mb_description": "Maximum size allowed for a mini-batch. Must be greater than a single record.",
      "batch_strategy": "Batch strategy - optional",
      "batch_strategy_description": "Maximum number of records per mini-batch.",      
      "max_invocation_retries": "Max invocation retries - optional",
      "max_invocation_retries_description": "The maximum number of retries when invocation requests are failing. Minimum value of 0. Maximum value of 3.",
      "invocation_timeout_in_seconds": "Invocation timeout in seconds - optional",
      "invocation_timeout_in_seconds_description": "The timeout value in seconds for an invocation request. Minimum value of 1. Maximum value of 3600.",
      "input_data_configuration": "Input data configuration",
      "s3_data_type": "S3 data type",
      "split_type": "Split type",
      "compression": "Compression",
      "content_type": "Content type - optional",
      "s3_location": "S3 location",
      "output_data_configuration": "Output data configuration",
      "s3_output_path": "S3 output path",
      "assemble_with": "Assemble with",
      "accept": "Accept - optional",
      "filtering_and_data_joins": "Input/output filtering and data joins - optional",
      "input_filter": "Input filter",
      "input_filter_description": "Filter input data prior to transform. Leave blank if you want to use all of the input source data.",
      "input_filter_hint": "Filter data by providing a JSON filter path or CSV column indices.",
      "join_source": "Join source",
      "join_source_description": "Choose the source of data to join with your output. Use Output filter to specify the final output.",
      "output_filter": "Output filter",
      "output_filter_description": "Filter output data after input/output join, if used. Leave blank if you want to use all of the output.",
      "output_filter_hint": "Filter data by providing a JSON filter path or CSV column indices.",
      "transform_job_summary": "Transform job summary",
      "job_configuration": "Job configuration",
      "attach_transform_job": "This will attach this transform job to current industrial model.",
      "detach_transform_job": "This will detach this transform job from current industrial model.",
      "stop_transform_job": "This will permanently stop your transform job and cannot be undone. This may affect other resources."
    },
    "pipeline": {
      "execution_arn": "Execution ARN",
      "pipeline_name": "Pipeline name",
      "pipeline_options": "Pipeline_options",
      "pipeline_option_byos": "Bring your own script with SageMaker built-in container image",
      "pipeline_option_byoc": "Bring your own container image",
      "Pipeline_step_pipeline": "Pipeline",
      "pipeline_step_train": "Train",
      "pipeline_step_deploy": "deploy",
      "pipeline_type": "Pipeline type",
      "pipeline_type_1": "Both training and inference and deploy in both cloud and edge",
      "pipeline_type_2": "Both training and inference and deploy only in cloud",
      "pipeline_type_3": "Only inference and deploy in both cloud and edge",
      "pipeline_type_4": "Only inference and deploy only in cloud"
    },
    "api": {
      "create_api": "Create REST API",
      "review_api": "Review REST API",
      "api_settings": "API Settings",
      "api_name": "API name",
      "api_gateway_options": "API gateway",
      "api_gateway_option_create_new": "Create new Rest API",
      "api_gateway_option_select_existed": "Select existing Rest API",
      "production_variant": "Production variants",
      "api_path": "API path",
      "api_stage": "API stage",
      "api_to_deploy": "APIs to deploy",
      "api_summary": "API summary",
      "rest_api_name": "Rest API name",
      "api_method": "API method"
    },
    "greengrass_component": {
      "create_greengrass_component": "Create component",
      "review_greengrass_component": "Review component",
      "create_greengrass_component_description": "When you finish your component, you can add it to AWS IoT Greengrass to deploy to core devices. Provide the component recipe and artifacts to create the component. This component is private and visible only to your AWS account.",
      "greengrass_component_settings": "Greengrass component settings",
      "component_name": "Component name",
      "production_variant": "Production variants",
      "model_name": "Model name",
      "component_version": "Component version",
      "component_version_arn": "Component version arn",
      "greengrass_component_summary": "Greengrass component version summary",
      "publisher": "Publisher",
      "description": "Description",
      "platforms": "Platforms",
      "greengrass_component_status": "Greengrass component status",
      "component_state": "Component state",
      "message": "Message",
      "errors": "Errors"
    },
    "greengrass_deployment": {
      "create_greengrass_deployment": "Create deployment",
      "review_greengrass_deployment": "Review Greengrass deploymen",
      "create_greengrass_deployment_description": "This deployment targets an AWS IoT thing group. Add a core device to the thing group to apply this deployment to it.",
      "greengrass_deployment_information": "Deployment information",
      "deployment_name": "Name - optional",
      "deployment_name_description": "A friendly name lets you identify this deployment. If you leave it blank, the deployment displays its ID instead of a name.",
      "deployment_name_hint": "The deployment name can have up to 255 characters.",
      "deployment_target": "Deployment target",
      "deployment_target_description": "You can deploy to a single Greengrass core device or a group of core devices.",
      "target_type": "Target type",
      "core_device": "Core device",
      "thing_group": "Thing group",
      "target_name": "Target name",
      "component_name": "Component name",
      "component_version": "Component version",
      "component_deployment_configuration": "Component deployment configuration",
      "deployment_id": "Deployment ID",
      "target_arn": "Target arn",
      "revision_id": "Revision ID",
      "iot_job": "IOT Job"
    }
  }
}